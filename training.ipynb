{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install adabelief-tf==0.2.0\n",
    "# pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "data_path = 'dataForClass.csv' # training data\n",
    "image_size=(48,48)\n",
    "\n",
    "def load_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    pixels = data['pixels'].tolist()\n",
    "    width, height = 48, 48\n",
    "    faces = []\n",
    "    for pixel_sequence in pixels:\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width, height)\n",
    "        face = cv2.resize(face.astype('uint8'),image_size)\n",
    "        faces.append(face.astype('float32'))\n",
    "    faces = np.asarray(faces)\n",
    "    faces = np.expand_dims(faces, -1)\n",
    "\n",
    "    emotions = pd.get_dummies(data['emotion']).values\n",
    "    return faces, emotions\n",
    "    \n",
    "faces, emotions = load_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view number of train images per class\n",
    "data = pd.read_csv(data_path)\n",
    "d = data['pixels'].count()\n",
    "data.groupby('emotion').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "ind = 23650\n",
    "f = faces[ind, :,:,0]\n",
    "# print('Emotion Labels', emotions[ind,:])\n",
    "plt.imshow(f, cmap='gray')\n",
    "emotion_dict =  {0: \"Angry\", 1: \"Disgusted\" ,2:\"Worried\", 3:\"Happy\", 4:\"Sad\", 5: \"Terrified\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "emotion_idx = np.argmax(emotions, axis=1)\n",
    "# Show first 25 training images below\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(faces[i, :, :, 0], cmap='gray')\n",
    "    plt.xlabel(emotion_dict[emotion_idx[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Imbalanced Data (By oversampling minority data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "oversample = SMOTE()\n",
    "label_emotion = data['emotion']\n",
    "y = LabelEncoder().fit_transform(label_emotion)\n",
    "tmp = faces.reshape((faces.shape[0], 48*48))\n",
    "x, y = oversample.fit_resample(tmp, y)\n",
    "tmp_x = x.reshape((x.shape[0], 48, 48, 1))\n",
    "tmp_y = pd.get_dummies(y).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "counter = Counter(y)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D, Conv2D, UpSampling2D, MaxPool2D, AveragePooling2D, Flatten, Dropout, BatchNormalization, MaxPooling2D, Activation, LSTM \n",
    "from tensorflow.keras.layers import SeparableConv2D, Reshape, Input, Lambda, Concatenate\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam, Nadam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from adabelief_tf import AdaBeliefOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(UpSampling2D(size=(2, 2), interpolation='nearest'))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1048, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1048, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batchsize = 128\n",
    "validation_batchsize = 128\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow(\n",
    "    x = tmp_x,\n",
    "    y = tmp_y,\n",
    "    shuffle = True,\n",
    "    batch_size=train_batchsize,\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = datagen.flow(\n",
    "    x = tmp_x,\n",
    "    y = tmp_y,\n",
    "    batch_size=validation_batchsize,\n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "optimizer = Nadam(learning_rate=1e-3, epsilon=1e-7)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='Brendon.h5', mode='max', monitor='val_acc', verbose=2, save_best_only=True)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=6, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.35, \n",
    "                                            min_lr=0.000003)\n",
    "\n",
    "callbacks_list = [checkpoint, learning_rate_reduction]\n",
    "\n",
    "epochs = 250\n",
    "\n",
    "model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch= train_generator.n/train_generator.batch_size ,\n",
    "      epochs=epochs,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.n/validation_generator.batch_size,\n",
    "      verbose=1,\n",
    "      callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model and weight (only submit best model)\n",
    "model_json = model.to_json()\n",
    "with open(\"Brendon.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
